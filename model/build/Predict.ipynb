{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABELS = [\"2-hands punch\", \"1-hand punch\", \"Standing\", \"Holding\"] \n",
    "current_directory = os.getcwd()\n",
    "project_path= os.path.abspath(os.path.join(current_directory, \"../..\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "LSTM_Model = tf.keras.models.load_model(f\"{project_path}/model/best/model.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO('yolov8n-pose.pt')\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "\n",
    "steps = 0\n",
    "lst_of_dct = {'key_1':[]}\n",
    "label = \" \"\n",
    "lst = []\n",
    "predictions_lst = []\n",
    "label_ = ''\n",
    "\n",
    "while True:\n",
    "\n",
    "    ret, image = cap.read()\n",
    "\n",
    "    results = model.predict(source=image, conf=0.4, classes= 0, device=0, save=False)\n",
    "    \n",
    "    boxes = results[0].boxes\n",
    "    result_keypoint = results[0].keypoints\n",
    "   \n",
    "    \n",
    "    if len(result_keypoint[0].xy[0]) == 0:\n",
    "        continue\n",
    "    else:\n",
    "        num = result_keypoint[0].xy[0].cpu().numpy()\n",
    "        num = num.reshape((1, 34))\n",
    "        \n",
    "        lst_of_dct['key_1'].append(num)\n",
    "        steps += 1\n",
    "        \n",
    "        if steps == 64:\n",
    "\n",
    "            steps = 0\n",
    "            lst=lst_of_dct['key_1']\n",
    "            lst_of_dct = {'key_1':[]}\n",
    "                \n",
    "            lst = np.array(lst)\n",
    "            lst = lst.reshape((1, 64, 34))\n",
    "            \n",
    "            preds = LSTM_Model.predict(lst)\n",
    "            \n",
    "            threshold = 0.8\n",
    "            predicted_probabilities = preds[0]\n",
    "            \n",
    "            max_prob = np.max(predicted_probabilities)\n",
    "        \n",
    "            if max_prob > threshold:\n",
    "                label = LABELS[np.argmax(preds)]\n",
    "                predictions_lst.append(label)\n",
    "            else:\n",
    "                label = \"NORMAL\"\n",
    "                predictions_lst.append(label)\n",
    "\n",
    "        image = cv2.putText(image, label, (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2)\n",
    "        image = cv2.resize(image, (1280, 720))\n",
    "        cv2.imshow(\"Prediction\", image)\n",
    "\n",
    "        key = cv2.waitKey(1)\n",
    "        if key == ord(\"a\"):\n",
    "            break\n",
    "\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO('yolov8n-pose.pt')\n",
    "\n",
    "# http://192.168.65.31:4747/video\n",
    "cap = cv2.VideoCapture(\"http://192.168.65.31:4747/video\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "steps = 0\n",
    "lst_of_dct = {'key_1':[],'key_2':[]}\n",
    "\n",
    "\n",
    "label = \" \"\n",
    "lst = []\n",
    "predictions_lst = []\n",
    "label_ = ''\n",
    "\n",
    "while True:\n",
    "  \n",
    "    # person1 = 0\n",
    "    # person2 = 0\n",
    "    minn = 1500\n",
    "    points = {}\n",
    "    i = 0\n",
    "\n",
    "    ret, image = cap.read()\n",
    "\n",
    "\n",
    "    results = model.predict(source=image, conf=0.60, classes= 0, device=0, save=False)\n",
    "    \n",
    "    boxes = results[0].boxes\n",
    "    result_keypoint = results[0].keypoints\n",
    "    image = cv2.putText(image, f\"there is {len(result_keypoint)}\", (100, 100), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2)\n",
    "    if len(result_keypoint) > 1:\n",
    "        key1 = 0\n",
    "        key2 = 0\n",
    "\n",
    "        for box in boxes:\n",
    "\n",
    "            coordinates = box.xyxy[0]\n",
    "\n",
    "            x_c = (coordinates[0] + coordinates[2]) // 2\n",
    "            y_c = (coordinates[1] + coordinates[3]) // 2\n",
    "            p = (x_c, y_c)\n",
    "\n",
    "            points[i] = [coordinates, p]\n",
    "\n",
    "            for k in points.keys():\n",
    "                if i != k:\n",
    "                    dis = ((points[i][1][0] - points[k][1][0]) ** 2 +\n",
    "                        (points[i][1][1] - points[k][1][1]) ** 2) ** 0.5\n",
    "\n",
    "                    if dis < minn:\n",
    "                        minn = dis\n",
    "                        # person1 = (int(points[i][1][0]), int(points[i][1][1]))\n",
    "                        # person2 = (int(points[k][1][0]), int(points[k][1][1]))\n",
    "                        key1 = i\n",
    "                        key2 = k\n",
    "                    \n",
    "            i += 1\n",
    "        if key1 == 0 and key2 == 0:\n",
    "            keys = []\n",
    "        else:\n",
    "            keys = [key1, key2]\n",
    "      \n",
    "        for z in range(len(keys)):\n",
    "\n",
    "            \n",
    "            num = result_keypoint[keys[z]].xy[0].cpu().numpy()\n",
    "            num = num.reshape((1, 34))\n",
    "        \n",
    "            if z==0:\n",
    "                lst_of_dct['key_1'].append(num)\n",
    "                steps += 1\n",
    "            if z==1:\n",
    "                lst_of_dct['key_2'].append(num)\n",
    "\n",
    "            if steps == 32:\n",
    "\n",
    "                if z==0:\n",
    "                    lst=lst_of_dct['key_1']\n",
    "                if z==1:\n",
    "                    lst=lst_of_dct['key_2']\n",
    "                    steps = 0\n",
    "                    lst_of_dct = {'key_1':[],'key_2':[]}\n",
    "\n",
    "                lst = np.array(lst)\n",
    "                lst = lst.reshape((1, 32, 34))\n",
    "                \n",
    "                preds = LSTM_Model.predict(lst)\n",
    "               \n",
    "\n",
    "                threshold = 0.94\n",
    "                predicted_probabilities = preds[0]\n",
    "\n",
    "                max_prob = np.max(predicted_probabilities)\n",
    "\n",
    "                if max_prob > threshold:\n",
    "                    \n",
    "                    label = LABELS[np.argmax(preds)]\n",
    "                    predictions_lst.append(label)\n",
    "                else:\n",
    "                    label = \"NORMAL\"\n",
    "                    predictions_lst.append(label)\n",
    "                \n",
    "                lst = []\n",
    "            if len(predictions_lst) == 8:\n",
    "                \n",
    "                if predictions_lst.count('BOXING')>=4:\n",
    "                    label_ = \"Violence\"\n",
    "                else:\n",
    "                    label_ = \"No Violence\"\n",
    "                predictions_lst=[]\n",
    "               \n",
    "            # else:\n",
    "            #     label_=\"proccessing\"\n",
    "    else:\n",
    "        label_=\"Only one person in image\"\n",
    "        predictions_lst = []\n",
    "\n",
    "    image = cv2.putText(image, label_, (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2)\n",
    "    \n",
    "    cv2.imshow(\"Prediction\", image)\n",
    "\n",
    "    key = cv2.waitKey(1)\n",
    "    if key == ord(\"a\"):\n",
    "        break\n",
    "\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yala",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
